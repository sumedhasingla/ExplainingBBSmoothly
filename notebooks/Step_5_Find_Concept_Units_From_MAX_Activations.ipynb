{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "import sys \n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = '/ocean/projects/asc170022p/singla/ExplainingBBSmoothly'\n",
    "mimic_file_name = os.path.join(main_dir, 'data', 'MIMIC_CXR_PA_AP_views_image_report_labels_concepts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(215518, 48)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_index</th>\n",
       "      <th>Reports</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Lung Lesion</th>\n",
       "      <th>Lung Opacity</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>...</th>\n",
       "      <th>hilar_opacity</th>\n",
       "      <th>interstitial_marking</th>\n",
       "      <th>enlarged_pulmonary_arteries</th>\n",
       "      <th>chf</th>\n",
       "      <th>pleural fluid</th>\n",
       "      <th>blunt</th>\n",
       "      <th>hilar_engorgement</th>\n",
       "      <th>air_bronchogram</th>\n",
       "      <th>heart size</th>\n",
       "      <th>pleural effusion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>No acute cardiopulmonary abnormality.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>No acute cardiopulmonary process.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   original_index                                Reports  No Finding  \\\n",
       "0               0  No acute cardiopulmonary abnormality.         1.0   \n",
       "1               1      No acute cardiopulmonary process.         1.0   \n",
       "\n",
       "   Enlarged Cardiomediastinum  Cardiomegaly  Lung Lesion  Lung Opacity  Edema  \\\n",
       "0                         0.0           0.0          0.0           0.0    0.0   \n",
       "1                         0.0           0.0          0.0           0.0    0.0   \n",
       "\n",
       "   Consolidation  Pneumonia  ...  hilar_opacity  interstitial_marking  \\\n",
       "0            0.0        0.0  ...             -1                    -1   \n",
       "1            0.0        0.0  ...             -1                    -1   \n",
       "\n",
       "   enlarged_pulmonary_arteries  chf  pleural fluid  blunt hilar_engorgement  \\\n",
       "0                           -1   -1             -1     -1                -1   \n",
       "1                           -1   -1             -1     -1                -1   \n",
       "\n",
       "  air_bronchogram heart size pleural effusion  \n",
       "0              -1         -1               -1  \n",
       "1              -1         -1               -1  \n",
       "\n",
       "[2 rows x 48 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mimic = pd.read_csv(mimic_file_name)\n",
    "print(df_mimic.shape)\n",
    "df_mimic.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_filename = os.path.join(main_dir, 'configs/Step_1_StanfordCheXpert_Classifier_256.yaml')\n",
    "config = yaml.load(open(config_filename))\n",
    "#for k in config.keys():\n",
    "#    print(k, config[k])\n",
    "categories = config['categories'].split(',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose a concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_name = 'cardiac silhouette'\n",
    "concept_dir = os.path.join(main_dir, config['log_dir'], config['name'],\n",
    "                           'Classifier_Output_MIMIC_Concepts', \n",
    "                            concept_name)\n",
    "try:\n",
    "    os.makedirs(concept_dir)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/ocean/projects/asc170022p/singla/ExplainingBBSmoothly/output/classifier/StanfordCheXpert_256/Classifier_Output_MIMIC_Concepts/cardiac silhouette'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concept_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1602, 8010)\n"
     ]
    }
   ],
   "source": [
    "positive_set = df_mimic.loc[df_mimic[concept_name] == 1]\n",
    "p = positive_set.shape[0] \n",
    "negative_set = df_mimic.loc[df_mimic[concept_name] == 0]\n",
    "n = negative_set.shape[0]\n",
    "negative_set = negative_set.sample(n = min(n,p * 5))\n",
    "print(p, negative_set.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((1602,), (8010,))\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    positive_file_names = np.asarray(positive_set[config['output_csv_names_column']])\n",
    "    negative_file_names = np.asarray(negative_set[config['output_csv_names_column']])\n",
    "    np.save(os.path.join(concept_dir, 'positive_names.npy'),positive_file_names)\n",
    "    np.save(os.path.join(concept_dir, 'negative_names.npy'),negative_file_names)\n",
    "else:\n",
    "    positive_file_names = np.load(os.path.join(concept_dir, 'positive_names.npy'),\n",
    "                                 allow_pickle=True)\n",
    "    negative_file_names = np.load(os.path.join(concept_dir, 'negative_names.npy'),\n",
    "                                 allow_pickle=True)\n",
    "print(positive_file_names.shape, negative_file_names.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to save the activations of these images, so that we can train a linear regressor on them.\n",
    "\n",
    "To do this, modify the config above to include:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = 'negative'\n",
    "config['batch_size'] = 50\n",
    "config['feature'] = True\n",
    "config['names'] = os.path.join(concept_dir, tmp+'_names.npy')\n",
    "config['output_folder_name'] = 'Classifier_Output_MIMIC_Concepts/'+concept_name\n",
    "config['partition'] = concept_name + '_' + tmp\n",
    "config_filename_1 =config_filename[:-5] + '_temp.yaml'\n",
    "with open(config_filename_1, 'w') as outfile:\n",
    "    yaml.dump(config, outfile, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python ExplainingBBSmoothly/Step_1_test_classifier.py -c /ocean/projects/asc170022p/singla/ExplainingBBSmoothly/configs/Step_1_StanfordCheXpert_Classifier_256_temp.yaml\n"
     ]
    }
   ],
   "source": [
    "cmd = ['python', 'ExplainingBBSmoothly/Step_1_test_classifier.py', '-c', config_filename_1]\n",
    "print(\" \".join(cmd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1100, 8, 8, 1024), (5500, 8, 8, 1024))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_feature = np.load(os.path.join(concept_dir, 'feature_dense_4_'+concept_name+'_positive.npy'))\n",
    "negative_feature = np.load(os.path.join(concept_dir, 'feature_dense_4_'+concept_name+'_negative.npy'))\n",
    "positive_feature.shape, negative_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1100, 1024), (5500, 1024))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Max the filters and save as CSV to be used in R-code\n",
    "positive_feature = np.max(positive_feature, axis=(1,2))\n",
    "negative_feature = np.max(negative_feature, axis=(1,2))\n",
    "positive_feature.shape, negative_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((550, 1024), (2750, 1024))\n",
      "((550, 1024), (2750, 1024))\n"
     ]
    }
   ],
   "source": [
    "# save half of the data as test set\n",
    "p = positive_feature.shape[0]\n",
    "n = negative_feature.shape[0]\n",
    "positive_feature_train = positive_feature[0:int(p/2),:]\n",
    "positive_feature_test = positive_feature[int(p/2):,:]\n",
    "negative_feature_train = negative_feature[0:int(n/2),:]\n",
    "negative_feature_test = negative_feature[int(n/2):,:]\n",
    "print(positive_feature_train.shape, negative_feature_train.shape)\n",
    "print(positive_feature_test.shape, negative_feature_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(os.path.join(concept_dir, 'feature_dense_4_'+concept_name+'_max_positive.csv'),\n",
    "        positive_feature_train,\n",
    "        delimiter=\",\")\n",
    "np.savetxt(os.path.join(concept_dir, 'feature_dense_4_'+concept_name+'_max_negative.csv'),\n",
    "        negative_feature_train,\n",
    "        delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run lasso regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_suffix = 'feature_dense_4_'+concept_name+'_max'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_file_name = os.path.join(main_dir, 'Step_5_Lasso_Regression.r')\n",
    "slurm_file_name = os.path.join(main_dir, 'jobs', 'slurmLauncher_LM.sh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/Rscript --vanilla /ocean/projects/asc170022p/singla/ExplainingBBSmoothly/Step_5_Lasso_Regression.r --concept_dir /ocean/projects/asc170022p/singla/ExplainingBBSmoothly/output/classifier/StanfordCheXpert_256/Classifier_Output_MIMIC_Concepts/cardiac silhouette --file_name feature_dense_4_cardiac silhouette_max --measure auc\n"
     ]
    }
   ],
   "source": [
    "cmd = ['/usr/bin/Rscript', '--vanilla',R_file_name,\\\n",
    "'--concept_dir',concept_dir, '--file_name', file_name_suffix,\\\n",
    "       '--measure', 'auc', ]\n",
    "#s = subprocess.check_output(cmd)\n",
    "print(\" \".join(cmd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the output of lasso regression to get the concept vector "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_features_max(text, label = 'X'):\n",
    "    \"\"\"\n",
    "    Get the non-zero Important Features - 1se Lambda \n",
    "    from the 10 lasso-classification runs \n",
    "    \"\"\"\n",
    "    text = text.replace(\"[1] \\\"(Intercept)\\\"\", \"\")\n",
    "    text = text.split(\"\\\"Important Features - 1se Lambda\\\"\")[1:]\n",
    "    text = [t.split('\\n[1]')[0] for t in text]\n",
    "    text[9] = text[9].split('\\n\\tStability ')[0]\n",
    "    text = [t.replace(\"\\n\", \"\") for t in text]\n",
    "    text = [t.replace(\"\\\"\", \"\") for t in text]\n",
    "    text = [re.sub(\"\\[\\d+\\]\", \"\", t) for t in text]\n",
    "    text = [t.strip() for t in text]\n",
    "    text = [t.split(label)[1:] for t in text]\n",
    "    text = [[int(tt) for tt in t] for t in text]\n",
    "    return text\n",
    "def get_lasso_coeff_max(text):\n",
    "    text = text.split(\"[1] \\\"Important Features Coeff - 1se Lambda\\\"\")[1:]\n",
    "    text = [t.split('[1] \\\"Important Features - Min Lambda\\\"')[0] for t in text]\n",
    "    text = [t.replace(\"\\n\", \"\") for t in text]\n",
    "    text = [t.replace(\"\\\"\", \"\") for t in text]\n",
    "    text = [t.replace(\"  \", \" \") for t in text]\n",
    "    text = [re.sub(\"\\[\\d+\\]\", \"\", t) for t in text]\n",
    "    text = [t.strip() for t in text]\n",
    "    text = [t.split(' ') for t in text]\n",
    "    \n",
    "    for i in range(0, len(text)):\n",
    "        temp = []\n",
    "        for j in range(len(text[i])):\n",
    "            try:\n",
    "                temp.append(float(text[i][j]))\n",
    "            except:\n",
    "                pass\n",
    "        text[i] = temp\n",
    "    return text\n",
    "def get_filters(features):\n",
    "    features = np.asarray(features)\n",
    "    features = features - 1\n",
    "    features = np.asarray(features)\n",
    "    return(features)\n",
    "def get_voting(features):\n",
    "    n = len(features)\n",
    "    feature_count = {}\n",
    "    for i in range(0, n):\n",
    "        for f in features[i]:\n",
    "            if feature_count.has_key(f):\n",
    "                feature_count[f]+=1\n",
    "            else:\n",
    "                feature_count[f] = 1\n",
    "    sorted_dict = (sorted(feature_count.items(), key = \n",
    "             lambda kv:[kv[1], kv[0]]))\n",
    "    sorted_dict.reverse()\n",
    "    return sorted_dict\n",
    "def choose_final_features(sorted_dict, n, thresh=0.5):\n",
    "    consider_features = []\n",
    "    for k in sorted_dict:\n",
    "        if k[1] >= (n*thresh):\n",
    "            consider_features.append(k)\n",
    "    consider_features =  np.asarray(consider_features)\n",
    "    return consider_features[:,0]\n",
    "\n",
    "def which_lasso(final_features, features):\n",
    "    num_common = []\n",
    "    for f in features:\n",
    "        l = set(final_features).intersection(set(f))\n",
    "        num_common.append(len(f) - len(l))\n",
    "    \n",
    "    index = np.where(num_common == np.min(num_common))[0]\n",
    "    max_f = 0\n",
    "    for i in range(index.shape[0]):\n",
    "        curr_index = index[i]\n",
    "        if len(features[curr_index]) > max_f:\n",
    "            max_f = len(features[curr_index])\n",
    "            selected = curr_index       \n",
    "    return selected\n",
    "\n",
    "def y_pred_from_lasso(lasso_coeff, features,data):\n",
    "    # f(x) = 1 + x_0 * beta_0 + ... + x_n-1 * beta_n-1\n",
    "    value = np.ones(data.shape[0]) * lasso_coeff[0]  #intercept\n",
    "    for i in range(len(features)):\n",
    "        value += data[:,features[i]-1] * lasso_coeff[i+1]\n",
    "    return value\n",
    "def get_auc(lasso_coeff, features,data,label):\n",
    "    from sklearn import metrics\n",
    "    value = y_pred_from_lasso(lasso_coeff, features,data)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(label, value, pos_label=1)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    cm = metrics.confusion_matrix(label, (value>0).astype(int))\n",
    "    recall = metrics.recall_score(label, (value>0).astype(int))\n",
    "    return auc, cm , recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get important units for a given concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = os.path.join(concept_dir, file_name_suffix+ '_output_R.txt')\n",
    "f1 = open(output_file)\n",
    "text = f1.read()\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_features = get_features_max(text)\n",
    "lasso_features_coeff = get_lasso_coeff_max(text)\n",
    "feature_count = get_voting(lasso_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1000, 10),\n",
       " (994, 10),\n",
       " (992, 10),\n",
       " (975, 10),\n",
       " (959, 10),\n",
       " (948, 10),\n",
       " (945, 10),\n",
       " (851, 10),\n",
       " (819, 10),\n",
       " (750, 10),\n",
       " (743, 10),\n",
       " (734, 10),\n",
       " (674, 10),\n",
       " (656, 10),\n",
       " (630, 10),\n",
       " (535, 10),\n",
       " (463, 10),\n",
       " (244, 10),\n",
       " (50, 10),\n",
       " (1, 10),\n",
       " (532, 9),\n",
       " (1003, 8),\n",
       " (958, 8),\n",
       " (636, 8),\n",
       " (296, 6),\n",
       " (202, 6),\n",
       " (152, 6),\n",
       " (971, 4),\n",
       " (767, 4),\n",
       " (342, 4),\n",
       " (320, 4),\n",
       " (235, 4),\n",
       " (126, 4),\n",
       " (957, 2),\n",
       " (911, 2),\n",
       " (904, 2),\n",
       " (883, 2),\n",
       " (826, 2),\n",
       " (787, 2),\n",
       " (665, 2),\n",
       " (658, 2),\n",
       " (608, 2),\n",
       " (468, 2),\n",
       " (418, 2),\n",
       " (380, 2),\n",
       " (331, 2),\n",
       " (225, 2),\n",
       " (117, 2),\n",
       " (42, 2)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Key: unit number value: number of independent lasso runs in which this \n",
    "# unit was select as important\n",
    "feature_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_features = choose_final_features(feature_count, len(lasso_features), thresh=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1000,  994,  992,  975,  959,  948,  945,  851,  819,  750,  743,\n",
       "        734,  674,  656,  630,  535,  463,  244,   50,    1,  532, 1003,\n",
       "        958,  636])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_choozen = which_lasso(final_features, lasso_features)\n",
    "lasso_choozen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the performance of this lasso regressor on the held out data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.append(positive_feature_test,\n",
    "                 negative_feature_test,\n",
    "                 axis=0)\n",
    "label = np.append(np.ones(positive_feature_test.shape[0]),\\\n",
    "                  np.zeros(negative_feature_test.shape[0]),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3300, 1024), (3300,))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9886095867768595, array([[2740,   10],\n",
       "        [  92,  458]]), 0.8327272727272728)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc,cm,recall = get_auc(lasso_features_coeff[lasso_choozen], \n",
    "                        lasso_features[lasso_choozen],\n",
    "                        data,\n",
    "                        label)\n",
    "auc,cm,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept units\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([   0,   49,  243,  462,  531,  534,  629,  635,  655,  673,  733,\n",
       "        742,  749,  818,  850,  944,  947,  957,  958,  974,  991,  993,\n",
       "        999, 1002])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Concept units\")\n",
    "get_filters(lasso_features[lasso_choozen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta/magnitude of importance for concept units\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.016468704,\n",
       " 0.146722841,\n",
       " -0.792116561,\n",
       " -0.106157447,\n",
       " -0.204449296,\n",
       " -0.021153695,\n",
       " 0.041747283,\n",
       " 0.091853432,\n",
       " 0.012680697,\n",
       " 0.051987369,\n",
       " -0.06384932,\n",
       " 0.120249635,\n",
       " 0.086339685,\n",
       " -0.223706198,\n",
       " 0.111918959,\n",
       " -0.57121582,\n",
       " 0.006738822,\n",
       " 0.308214648,\n",
       " 0.000494669,\n",
       " 0.04723585,\n",
       " 0.09902543,\n",
       " 0.081826857,\n",
       " -0.014118703,\n",
       " 0.165001617,\n",
       " 0.029055321]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Beta/magnitude of importance for concept units\")\n",
    "lasso_features_coeff[lasso_choozen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda",
   "language": "python",
   "name": "anaconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
